{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "ioDownload = (fName, txt) => {\n",
       "    var element = document.createElement('a');\n",
       "    element.setAttribute('href', 'data:text/plain;charset=utf-8,' + encodeURIComponent(txt));\n",
       "    element.setAttribute('download', fName);\n",
       "\n",
       "    element.style.display = 'none';\n",
       "    element.click();\n",
       "}\n",
       "\n",
       "ioJupOutput = (outType, txtType, txt) => {\n",
       "  let output = {\n",
       "    'output_type': outType\n",
       "  }\n",
       "  if (outType == 'stream') {\n",
       "    output['name'] = 'stdout'\n",
       "    output['text'] = [txt]\n",
       "  }\n",
       "  else {\n",
       "    output['data'] = {}\n",
       "    output['data'][txtType] = [txt]\n",
       "  }\n",
       "  return output\n",
       "}\n",
       "\n",
       "ioJoinStr = (txtArr, sep) => {\n",
       "  let result = ''\n",
       "  let isSkip = true\n",
       "  txtArr.forEach((txt, i) => {\n",
       "    if (txt.trim().length == 0 && isSkip == true)\n",
       "      return\n",
       "    isSkip = false\n",
       "    result += txt\n",
       "    if (i < txtArr.length - 1)\n",
       "      result += sep\n",
       "  })\n",
       "  return result\n",
       "}\n",
       "\n",
       "ioGetOutput = (codeNode) => {\n",
       "  let n = codeNode\n",
       "  while (n.classList.length != 0)\n",
       "    n = n.parentNode\n",
       "  outputNodes = n.querySelectorAll('.tableDisplay')\n",
       "  let outputs = []\n",
       "  outputNodes.forEach(n => {\n",
       "    let txtNode = n.querySelector('.plainTextContent')\n",
       "    if (txtNode != null) {\n",
       "      outputs.push({\n",
       "        'outType': 'stream',\n",
       "        'dType': null,\n",
       "        'txt': txtNode.innerText\n",
       "      })\n",
       "      return\n",
       "    }\n",
       "    let htmlNode = n.querySelector('.resultContained')\n",
       "    if (htmlNode != null)\n",
       "      outputs.push({\n",
       "        'outType': 'execute_result',\n",
       "        'dType': 'text/html',\n",
       "        'txt': htmlNode.innerHTML\n",
       "      })\n",
       "  })\n",
       "  return outputs\n",
       "}\n",
       "\n",
       "ioJupDownload = () => {\n",
       "    codeContainers = document.querySelectorAll('.ace_layer.ace_text-layer')\n",
       "\n",
       "    let txtCellTempl = {\n",
       "        \"cell_type\": null,\n",
       "        \"execution_count\": 0,\n",
       "        \"metadata\": {},\n",
       "        \"outputs\": [\n",
       "        ],\n",
       "        \"source\": [\n",
       "        ]\n",
       "    }\n",
       "\n",
       "    let jup = {\n",
       "        \"cells\": [],\n",
       "        \"metadata\": {\n",
       "        },\n",
       "        \"nbformat\": 4,\n",
       "        \"nbformat_minor\": 2\n",
       "    }\n",
       "\n",
       "    codeContainers.forEach(container => {\n",
       "        let codes = []\n",
       "        container.childNodes.forEach(lineGroup => {\n",
       "            let line = []\n",
       "            lineGroup.childNodes.forEach((o, i) => {\n",
       "              if (i > 0)\n",
       "                line.push(o.innerText.trim())\n",
       "              else\n",
       "                line.push(o.innerText)\n",
       "            })\n",
       "            codes.push(line.join(''))\n",
       "        })\n",
       "        if (codes.length == 0)\n",
       "          return\n",
       "        let txtCell = structuredClone(txtCellTempl)\n",
       "        if (codes[0].length > 0 && codes[0][0] != '%') {\n",
       "            codes = ioJoinStr(codes, '\\n')\n",
       "            txtCell['cell_type'] = 'code'\n",
       "        }\n",
       "        else if (codes[0].length >= 8 && codes[0].substring(0, 8) == '%pyspark') {\n",
       "            codes = ioJoinStr(codes.slice(1), '\\n')\n",
       "            txtCell['cell_type'] = 'code'\n",
       "        }\n",
       "        else if (codes[0].length == 3 && codes[0].substring(0, 3) == '%md') {\n",
       "            codes = ioJoinStr(codes.slice(1), '\\n')\n",
       "            txtCell['cell_type'] = 'markdown'\n",
       "        }\n",
       "        else return\n",
       "\n",
       "        if (txtCell['cell_type'] == 'code') {\n",
       "          ioGetOutput(container).forEach(o => {\n",
       "            txtCell['outputs'].push(ioJupOutput(o['outType'], o['dType'], o['txt']))\n",
       "          })\n",
       "        }\n",
       "        txtCell['source'].push(codes)\n",
       "        jup['cells'].push(txtCell)\n",
       "    })\n",
       "\n",
       "    let fName = document.querySelector('.notebook-actionBar-title').innerText.replace('/', '_') + '.ipynb'\n",
       "    ioDownload(fName, JSON.stringify(jup))\n",
       "}\n",
       "  </script><button class=\"btn btn-primary\" onclick=\"ioJupDownload()\">Download ipynb</button>\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.jup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CPU---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: 1.6%\t#1: 0.0%\t#2: 6.2%\n",
      "#3: 1.6%\t#4: 6.2%\t#5: 0.0%\n",
      "#6: 3.1%\t#7: 0.0%\t#8: 0.0%\n",
      "#9: 1.6%\t#10: 4.7%\t#11: 3.1%\n",
      "#12: 1.6%\t#13: 4.7%\t#14: 1.6%\n",
      "#15: 0.0%\t#16: 0.0%\t#17: 0.0%\n",
      "#18: 1.6%\t#19: 1.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Memory---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46360MiB (71%) free, 65237MiB total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---GPU---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0. Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory: 648MiB (3%) free, 16287MiB total\n",
      "(46360, [648])\n"
     ]
    }
   ],
   "source": [
    "z.showUsage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import multiprocessing\n",
    "\n",
    "from flask import Flask, request, send_file, jsonify\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_qdrant import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "from tempfile import NamedTemporaryFile\n",
    "from httpx import TimeoutException\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "GEMMA2_MODEL = \"gemma-2-9b-it-Q5_K_L.gguf\"\n",
    "# GEMMA2_MODEL = r\"C:\\Users\\wwhac\\Downloads\\gemma-2-9b-it-Q5_K_L.gguf\"\n",
    "\n",
    "EMBEDDINGS_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# EMBEDDINGS_MODEL = \"vinai/PhoGPT-4B-Chat\"\n",
    "\n",
    "DASHBOARD = \n",
    "QDRANT_URL = \n",
    "QDRANT_API_KEY = \n",
    "\n",
    "COLLECTION_NAME = \"DATA-SOC\"\n",
    "CONTENT_PAYLOAD_KEY = \"content\"\n",
    "METADATA_PAYLOAD_KEY = \"metadata\"\n",
    "\n",
    "SAVE_PATH = '../data-store'\n",
    "BATCH_SIZE_UPLOAD = 10\n",
    "\n",
    "TOP_K = 5\n",
    "MAX_SAME_QUERY = 1\n",
    "MAX_DOCS_FOR_CONTEXT = (MAX_SAME_QUERY + 1) * TOP_K\n",
    "\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "gemma_2_model = ChatLlamaCpp(\n",
    "    model_path=GEMMA2_MODEL,\n",
    "    verbose=False, \n",
    "    temperature=0.5,\n",
    "    n_gpu_layers=-1,  # Avoid using GPU layers if GPU memory is insufficient\n",
    "    n_ctx=4096,  # Reduce context window size to decrease memory usage\n",
    "    max_tokens=4096,  # Adjust max tokens to match reduced context\n",
    "    f16_kv=False,  # Disable fp16 key/value caches to save memory\n",
    "    n_threads=multiprocessing.cpu_count()-1,  # Use fewer CPU threads\n",
    ")\n",
    "\n",
    "app = Flask(\n",
    "    \"SOC-API-CHATBOT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---llms response----\n",
    "async def llms_process_template(template: str):\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[]\n",
    "    )\n",
    "    \n",
    "    chain = (\n",
    "        prompt \n",
    "        | gemma_2_model \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    response = await chain.ainvoke({})\n",
    "    return response\n",
    "\n",
    "#---End---llms response----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---query----\n",
    "def collection_exists(client: QdrantClient, collection_name: str) -> bool:\n",
    "    \"\"\"Check if a Qdrant collection exists\"\"\"\n",
    "    collections = client.get_collections().collections\n",
    "    return any(col.name == collection_name for col in collections)\n",
    "\n",
    "def existing_collection(collection_name: str) -> Qdrant:\n",
    "    \"\"\"Create vector retriever\"\"\"\n",
    "    \n",
    "    client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "    if not collection_exists(client, collection_name):\n",
    "        return None\n",
    "    \n",
    "\n",
    "    doc_store = Qdrant.from_existing_collection(\n",
    "        url=QDRANT_URL,\n",
    "        api_key=QDRANT_API_KEY,\n",
    "        embedding=embeddings,\n",
    "        collection_name=collection_name,    \n",
    "        content_payload_key=CONTENT_PAYLOAD_KEY,\n",
    "        metadata_payload_key=METADATA_PAYLOAD_KEY\n",
    "    )\n",
    "    return doc_store\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Rerank docs (reciprocal rank fusion)\"\"\"\n",
    "\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    return [x[0] for x in reranked_results[:MAX_DOCS_FOR_CONTEXT]]\n",
    "\n",
    "async def query_generator(original_query: dict) -> list[str]:\n",
    "    \"\"\"Generate queries from original query\"\"\"\n",
    "\n",
    "    user_query = original_query.get(\"user_query\")\n",
    "    template = f\"\"\"\n",
    "        Đưa ra {MAX_SAME_QUERY} câu hỏi cùng sát với ý nghĩa câu sau: {user_query}. \n",
    "        Chỉ sinh bằng tiếng Việt Nam, không sinh thêm văn bản gì!\n",
    "    \"\"\"\n",
    "\n",
    "    queries = await llms_process_template(template)\n",
    "    queries = (lambda x: x.split(\"\\n\"))(queries)\n",
    "    queries = ((lambda lines: [line.strip() for line in lines if line.strip() != \"\"]))(queries)\n",
    "    queries.insert(0, \"0. \" + user_query)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "async def similarity_search(para: dict) -> list[Document]:\n",
    "    \"\"\"RRF retriever\"\"\"\n",
    "\n",
    "    common_doc_store = existing_collection(COLLECTION_NAME)\n",
    "    user_doc_store = existing_collection(para[\"user_id\"])\n",
    "    queries = await query_generator(para)\n",
    "    \n",
    "    all_results = []\n",
    "    for q in queries:\n",
    "        if common_doc_store:\n",
    "            common_results = common_doc_store.similarity_search_with_score(q, k=TOP_K)\n",
    "            all_results.append(common_results)\n",
    "\n",
    "        if user_doc_store:\n",
    "            user_results = user_doc_store.similarity_search_with_score(q, k=TOP_K)\n",
    "            all_results.append(user_results)\n",
    "    \n",
    "    fused_results = reciprocal_rank_fusion(all_results)\n",
    "    return fused_results\n",
    "\n",
    "async def query(user_query: str, user_id: str):\n",
    "    \"\"\"Query with vector db\"\"\"\n",
    "\n",
    "    ssearch = RunnableLambda(similarity_search)\n",
    "    context = await ssearch.ainvoke({'user_query': user_query, 'user_id': user_id})\n",
    "    context = [c[0].page_content for c in context]\n",
    "    question = user_query\n",
    "\n",
    "    template = f\"\"\"\n",
    "        Vui lòng trả lời [câu hỏi] chỉ bằng [thông tin] sau.\n",
    "        Thông tin: {context}\n",
    "        Câu hỏi: {question}\n",
    "        Câu trả lời cuối cùng:\n",
    "    \"\"\"\n",
    "\n",
    "    response = await llms_process_template(template)   \n",
    "    result = {\"context\": context, \"response\": response, \"template\": template}\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---upload----\n",
    "def check_file_existed(folder, filename):\n",
    "    file_path = os.path.join(SAVE_PATH, folder, filename)\n",
    "    file_existed = os.path.exists(file_path)\n",
    "    \n",
    "    if file_existed:\n",
    "        return file_path\n",
    "    return None\n",
    "\n",
    "async def save_pdf(file, user_id):\n",
    "    if not os.path.exists(SAVE_PATH):\n",
    "        os.makedirs(SAVE_PATH)\n",
    "\n",
    "    folder = SAVE_PATH + \"/\" + user_id\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    pdf_content = file.read()\n",
    "    file_name = file.filename\n",
    "\n",
    "    with NamedTemporaryFile(delete=False, dir=folder, suffix='.pdf') as temp_file:\n",
    "        temp_file.write(pdf_content)\n",
    "        temp_file.close()\n",
    "        file_name_temp = temp_file.name\n",
    "    \n",
    "    file_abs_path = os.path.abspath(os.path.join(folder, file_name))\n",
    "    os.rename(file_name_temp, file_abs_path)\n",
    "    \n",
    "    return file_abs_path\n",
    "    \n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def upload_to_qdrant(docs, user_id):\n",
    "    try:\n",
    "        Qdrant.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            url=QDRANT_URL,\n",
    "            api_key=QDRANT_API_KEY,\n",
    "            collection_name=user_id,\n",
    "            content_payload_key=CONTENT_PAYLOAD_KEY,\n",
    "            metadata_payload_key=METADATA_PAYLOAD_KEY,\n",
    "        )\n",
    "    except TimeoutException as e:\n",
    "        print(f\"Timeout occurred: {e}\")\n",
    "        raise \n",
    "\n",
    "async def upload_pdf(file_path, user_id):\n",
    "    text_splitter = SemanticChunker(embeddings=embeddings, breakpoint_threshold_type=\"percentile\")\n",
    "    raw_documents = PyPDFLoader(file_path).load()\n",
    "    docs = text_splitter.split_documents(raw_documents)\n",
    "    \n",
    "    for i in range(0, len(docs), BATCH_SIZE_UPLOAD):\n",
    "        batch = docs[i:i + BATCH_SIZE_UPLOAD]\n",
    "        try:\n",
    "            upload_to_qdrant(batch, user_id)\n",
    "        except TimeoutException:\n",
    "            print(f\"Failed to upload batch {i // BATCH_SIZE_UPLOAD + 1}. Moving to the next batch.\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "#---End---upload----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---API----\n",
    "@app.route(\"/ask\", methods=[\"POST\"])\n",
    "async def post_ask():\n",
    "    user_id = request.form['user_id']\n",
    "    user_query = request.form['user_query']\n",
    "    file = request.files.get('file')\n",
    "    \n",
    "    if file and file.filename:\n",
    "        print('Yes')\n",
    "    else: \n",
    "        print('No')\n",
    "    \n",
    "    answer = await query(user_query, user_id)    \n",
    "    return jsonify({\n",
    "        \"message\": user_query,\n",
    "        \"answer\": answer['response']\n",
    "    }, 200)\n",
    "\n",
    "@app.route(\"/query\", methods=[\"POST\"])\n",
    "async def post_answer():\n",
    "    data = request.get_json()\n",
    "    user_query = data.get(\"user_query\")\n",
    "    user_id = data.get(\"user_id\")\n",
    "\n",
    "    answer = await query(user_query, user_id)\n",
    "    return jsonify({\n",
    "        \"message\": user_query,\n",
    "        \"answer\": answer['response'],\n",
    "        \"context\": answer['context'],\n",
    "        \"template\": answer['template']\n",
    "    }), 200\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "async def post_upload():\n",
    "    user_id = request.form.get('user_id')\n",
    "\n",
    "    if 'file' in request.files and user_id:\n",
    "        file = request.files['file']\n",
    "        file_existed = check_file_existed(user_id, file.filename)\n",
    "        \n",
    "        if file_existed:\n",
    "            with open(file_existed, 'rb') as file:\n",
    "                return send_file(file_existed, as_attachment=True, download_name=file.name)\n",
    "        else:\n",
    "            file_path = await save_pdf(file, user_id)\n",
    "            upload_success = await upload_pdf(file_path, user_id)\n",
    "            if upload_success:\n",
    "                return {\n",
    "                    'response': 'Tải lên thành công!'\n",
    "                }, 200\n",
    "    \n",
    "    return {\n",
    "        'response': 'Tải lên file không thành công, vui lòng kiểm tra lại file pdf của bạn!'\n",
    "    }, 200\n",
    "\n",
    "@app.route(\"/llms\", methods=[\"POST\"])\n",
    "async def post_llms():\n",
    "    data = request.get_json()\n",
    "    template = data.get(\"template\")\n",
    "\n",
    "    response = await llms_process_template(template)\n",
    "    return jsonify({\n",
    "        \"response\": response\n",
    "    }), 200\n",
    "    \n",
    "@app.route(\"/test\", methods=[\"POST\"])\n",
    "async def post_test():\n",
    "    data = request.get_json()\n",
    "    template = data.get(\"template\")\n",
    "    return template\n",
    "    \n",
    "@app.route(\"/test\", methods=[\"GET\"])\n",
    "async def get_test():\n",
    "    return \"This is a hello world page\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.net.SocketException: Connection reset\n",
      "\tat java.net.SocketInputStream.read(SocketInputStream.java:210)\n",
      "\tat java.net.SocketInputStream.read(SocketInputStream.java:141)\n",
      "\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n",
      "\tat java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\n",
      "\tat java.io.BufferedInputStream.read(BufferedInputStream.java:345)\n",
      "\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)\n",
      "\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n",
      "\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n",
      "\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n",
      "\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n",
      "\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n",
      "\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n",
      "\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n",
      "\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n",
      "\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n",
      "\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n",
      "\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n",
      "\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\n",
      "\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n",
      "\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(app.run(debug=False, host=\"0.0.0.0\", port=7733, use_reloader=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
