{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported psutil 6.0.0 (pre-installed)\n",
      "Imported torch 2.5.1+cu121 (pre-installed)\n",
      "---CPU---\n",
      "#0: 1.6%\t#1: 1.6%\t#2: 4.6%\n",
      "#3: 3.1%\t#4: 0.0%\t#5: 3.1%\n",
      "#6: 4.7%\t#7: 1.6%\t#8: 0.0%\n",
      "#9: 0.0%\t#10: 1.6%\t#11: 6.2%\n",
      "#12: 0.0%\t#13: 6.2%\t#14: 0.0%\n",
      "#15: 0.0%\t#16: 0.0%\t#17: 4.8%\n",
      "#18: 0.0%\t#19: 1.5%\n",
      "\n",
      "---Memory---\n",
      "45121MiB (69%) free, 65237MiB total\n",
      "\n",
      "---GPU---\n",
      "#0. Tesla P100-PCIE-16GB\n",
      "memory: 1209MiB (7%) free, 16287MiB total\n",
      "Free VRAM: 1209MB\n",
      "Optimize n_layer1: 5\n",
      "Optimize n_layer2: None\n"
     ]
    }
   ],
   "source": [
    "# Lựa chọn n_layer tối ưu. Dựa trên dung lượng VRAM đang trống. \n",
    "# Với Gemma 2 9b, Mỗi layer chiếm khoảng 240MB \n",
    "\n",
    "# Xóa llm \n",
    "if 'llm' in locals(): del llm\n",
    "if 'llms_summary' in locals(): del llms_summary\n",
    "if 'llms_evaluate' in locals(): del llms_evaluate\n",
    "\n",
    "# Lấy VRAM còn trống \n",
    "_, free_GPUs = z.showUsage()\n",
    "print(f'Free VRAM: {free_GPUs[0]}MB')\n",
    "\n",
    "n_layer1 = int(free_GPUs[0] / 240)\n",
    "n_layer2 = 0\n",
    "\n",
    "if n_layer1 == 0:\n",
    "    print(f'Sufficient VRAM (n_layer=={n_layer}), use CPU')\n",
    "    n_layer1 = None\n",
    "    n_layer2 = None\n",
    "    \n",
    "else:\n",
    "    if n_layer1 > 43:\n",
    "        n_layer2 = n_layer1 - 43\n",
    "        n_layer1 = 43\n",
    "        \n",
    "    elif n_layer1 == 43:\n",
    "        n_layer1 = 40\n",
    "        \n",
    "    elif n_layer2 > 20:\n",
    "        n_layer1 = 40\n",
    "        n_layer2 = 20\n",
    "        \n",
    "    else:\n",
    "        n_layer2 = None\n",
    "            \n",
    "# n_layer1 = n_layer2 = (n_layer1 + n_layer2) // 2 - 1  \n",
    "print(f'Optimize n_layer1: {n_layer1}')\n",
    "print(f'Optimize n_layer2: {n_layer2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uvicorn\n",
    "import asyncio\n",
    "import multiprocessing\n",
    "\n",
    "from uvicorn import Config, Server\n",
    "from fastapi import FastAPI, File, UploadFile, Form, BackgroundTasks, Depends\n",
    "from fastapi.responses import JSONResponse, StreamingResponse, FileResponse\n",
    "\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain_community.embeddings import LlamaCppEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from tempfile import NamedTemporaryFile\n",
    "from httpx import TimeoutException\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from werkzeug.datastructures import FileStorage\n",
    "from fpdf import FPDF\n",
    "\n",
    "# EMBEDDINGS_MODEL = \"dunzhang/stella_en_1.5B_v5\"\n",
    "# EMBEDDINGS_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# EMBEDDINGS_MODEL = \"keepitreal/vietnamese-sbert\"\n",
    "EMBEDDINGS_MODEL = \"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\"\n",
    "GEMMA2_MODEL = \"soc-models/gemma-2-9b-it-Q6_K_L.gguf\"\n",
    "\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "n_threads1 = (multiprocessing.cpu_count() - 1 ) // 2\n",
    "n_threads2 = (multiprocessing.cpu_count() - 1 ) // 2\n",
    "\n",
    "llms_summary = ChatLlamaCpp(\n",
    "    model_path=GEMMA2_MODEL,\n",
    "    verbose=False, \n",
    "    temperature=0,\n",
    "    n_ctx=8192,  \n",
    "    max_tokens=1024,  \n",
    "    f16_kv=False,  \n",
    "    n_gpu_layers=n_layer1,  \n",
    "    n_threads=n_threads1,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "llms_evaluate = ChatLlamaCpp(\n",
    "    model_path=GEMMA2_MODEL,\n",
    "    verbose=False, \n",
    "    temperature=0,\n",
    "    n_ctx=8192,  \n",
    "    max_tokens=1024,  \n",
    "    f16_kv=False,  \n",
    "    n_gpu_layers=n_layer2,  \n",
    "    n_threads=n_threads2,\n",
    "    streaming=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---llms response----\n",
    "\n",
    "def process_template(template: str) -> str:\n",
    "    template = template.replace(\"{\", \"{{\")\n",
    "    template = template.replace(\"}\", \"}}\")\n",
    "    return template\n",
    "\n",
    "def create_prompt(template: str) -> PromptTemplate:\n",
    "    processed_template = process_template(template)\n",
    "    \n",
    "    return PromptTemplate(\n",
    "        template=processed_template,\n",
    "        input_variables=[]\n",
    "    )\n",
    "\n",
    "def get_chain(template: str, is_summary: bool=True):\n",
    "    prompt = create_prompt(template)\n",
    "    chain = None\n",
    "    \n",
    "    if is_summary:\n",
    "        chain = (\n",
    "            prompt \n",
    "            | llms_summary \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    else:\n",
    "        chain = (\n",
    "            prompt \n",
    "            | llms_evaluate \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    return chain\n",
    "    \n",
    "async def generate_result(template: str, is_summary: bool) -> str:\n",
    "    chain = get_chain(template, is_summary)\n",
    "    response = await chain.ainvoke({})\n",
    "    return response\n",
    "\n",
    "async def generate_stream_json(template: str, is_summary: bool) -> str:\n",
    "    chain = get_chain(template, is_summary)\n",
    "    result = \"\"\n",
    "    async for chunk in chain.astream({}):\n",
    "        result += chunk\n",
    "        yield json.dumps({\n",
    "            \"response\": chunk,\n",
    "            \"success\": True\n",
    "        }) + \"\\n\"\n",
    "    print(\"result: \", result)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "async def generate_stream_str(template: str, is_summary: bool) -> str:\n",
    "    chain = get_chain(template, is_summary)\n",
    "    \n",
    "    async for chunk in chain.astream({}):\n",
    "        yield chunk\n",
    "\n",
    "#---End---llms response----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "from email.message import EmailMessage\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Thông tin xác thực\n",
    "ACCESS_TOKEN = \"\"\n",
    "REFRESH_TOKEN = \"\"\n",
    "CLIENT_ID = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "TOKEN_URI = \"\"\n",
    "\n",
    "def get_email_receiver(user_query: str):\n",
    "    email_regex = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    emails = re.findall(email_regex, text)\n",
    "    return emails\n",
    "\n",
    "def get_credentials():\n",
    "    \"\"\"Tạo thông tin xác thực từ các khóa trực tiếp.\"\"\"\n",
    "    creds = Credentials(\n",
    "        token=ACCESS_TOKEN,\n",
    "        refresh_token=REFRESH_TOKEN,\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        token_uri=TOKEN_URI\n",
    "    )\n",
    "    if creds.expired:\n",
    "        creds.refresh(Request())\n",
    "    return creds\n",
    "\n",
    "def send_email_with_attachment(receiver: str, file_evaluation_name: str, file_path: str):\n",
    "    \"\"\"Gửi email với nội dung và tệp đính kèm.\"\"\"\n",
    "    creds = get_credentials()\n",
    "    service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "\n",
    "    # Tạo email\n",
    "    mime_message = EmailMessage()\n",
    "    mime_message[\"To\"] = receiver\n",
    "    mime_message[\"From\"] = \"147.qter@gmail.com\"\n",
    "    mime_message[\"Subject\"] = \"Information Security Evaluation About SOC 2 Type II\"\n",
    "    mime_message.set_content(f\"This is an email with an attachment that is a PDF file of a SOC 2 Type report security assessment based on the {file_evaluation_name} file you provided!\")\n",
    "\n",
    "    # Thêm tệp đính kèm\n",
    "    content_type, _ = mimetypes.guess_type(file_path)\n",
    "    maintype, subtype = content_type.split(\"/\")\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        mime_message.add_attachment(f.read(), maintype, subtype, filename=file_evaluation_name)\n",
    "\n",
    "    # Mã hóa email\n",
    "    encoded_message = base64.urlsafe_b64encode(mime_message.as_bytes()).decode()\n",
    "    body = {\"raw\": encoded_message}\n",
    "\n",
    "    # Gửi email\n",
    "    try:\n",
    "        message = service.users().messages().send(userId=\"me\", body=body).execute()\n",
    "        print(f\"Message sent successfully! ID: {message['id']}\")\n",
    "        return True\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---query----\n",
    "\n",
    "QA_COLLECTION = \"QA_DATA\"\n",
    "COMMON_COLLECTION = \"COMMON_DATA\"\n",
    "\n",
    "CONTENT_PAYLOAD_KEY = \"content\"\n",
    "METADATA_PAYLOAD_KEY = \"metadata\"\n",
    "DB_DIRECTORY = \"./soc-data-store/\"\n",
    "\n",
    "MAX_DOCS_FOR_QA_DATA = 3\n",
    "MAX_DOCS_FOR_COMMON_DATA = 3\n",
    "MAX_DOCS_FOR_USER_FILE = 3\n",
    "BATCH_SIZE_UPLOAD = 5000\n",
    "\n",
    "def get_check_is_userquery_about_userfile_template(user_query: str):\n",
    "    template = f\"\"\"\n",
    "        Are you a chatbot that classifies whether the provided \"user query\" is a query that is intended to retrieve content from a document, report, file, or file that the user has uploaded?\n",
    "        Instructions: Just look for words like: document, report, file, or a variation of those words in the query.\n",
    "        \n",
    "        **Required:**\n",
    "        **Do not create any additional content.**\n",
    "        **The final answer is True or False.**\n",
    "        **If there is no result or cannot be evaluated or the result is unclear and ambiguous during evaluation, the answer must be: False**\n",
    "        \n",
    "        User query: {user_query}\n",
    "        \n",
    "        Input example 1: Summarize the information in the above report\n",
    "        Output example 1: True\n",
    "        \n",
    "        Input example 2: What is 2-FA encryption?\n",
    "        Output Example 2: False\n",
    "        \n",
    "        Input Example 3: Evaluate the contents of the above file\n",
    "        Output Example 3: True\n",
    "    \"\"\"\n",
    "    return template\n",
    "\n",
    "async def check_is_userquery_about_userfile(user_query: str):\n",
    "    template = get_check_is_userquery_about_userfile_template(user_query)\n",
    "    result = await generate_result(template, True)\n",
    "    result = result.lower().strip()\n",
    "    print(\"check_is_userquery_about_userfile: \", result)\n",
    "    \n",
    "    if result.lower() == \"true\": return True\n",
    "    return False\n",
    "\n",
    "def existing_collection(collection_name: str) -> Chroma:\n",
    "    \"\"\"Create vector retriever\"\"\"\n",
    "    db_directory = os.path.join(DB_DIRECTORY, collection_name)\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=db_directory,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "async def similarity_search(para: dict) -> list[Document]:\n",
    "    \"\"\"RRF retriever\"\"\"\n",
    "    qa_doc_store = existing_collection(QA_COLLECTION)\n",
    "    common_doc_store = existing_collection(COMMON_COLLECTION)\n",
    "    user_doc_store = existing_collection(para[\"user_id\"])\n",
    "    \n",
    "    is_question_about_file = await check_is_userquery_about_userfile(para[\"user_query\"])\n",
    "    all_results = []\n",
    "        \n",
    "    if is_question_about_file:\n",
    "        user_results = user_doc_store.similarity_search_with_score(para[\"user_query\"], k=MAX_DOCS_FOR_USER_FILE)\n",
    "        print(\"user_results: \", user_results)\n",
    "        all_results.extend(user_results)\n",
    "    else: \n",
    "        qa_results = qa_doc_store.similarity_search_with_score(para[\"user_query\"], k=MAX_DOCS_FOR_QA_DATA)\n",
    "        print(\"qa_results: \", qa_results)\n",
    "        all_results.extend(qa_results)\n",
    "        \n",
    "        common_results = common_doc_store.similarity_search_with_score(para[\"user_query\"], k=MAX_DOCS_FOR_COMMON_DATA)\n",
    "        print(\"common_results: \", common_results)\n",
    "        all_results.extend(common_results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "async def get_ask_template(user_id: str, user_query: str) -> str:\n",
    "    ssearch = RunnableLambda(similarity_search)\n",
    "    context = await ssearch.ainvoke({\"user_id\": user_id, \"user_query\": user_query})\n",
    "    context = [c[0].page_content for c in context]\n",
    "    question = user_query\n",
    "    \n",
    "    template = f\"\"\"\n",
    "        You are a support chatbot providing information about information security and network security.\n",
    "        You are a chatbot that provides information about information security and cybersecurity.\n",
    "\n",
    "        **Required:*\n",
    "        **If it is a greeting question, please respond politely to the user as a chatbot that provides information about information security and cybersecurity, following the structure defined below.**\n",
    "        **If the question is not related to information about information security and cybersecurity, please ask the user to ask again, following the structure defined below.**\n",
    "        **Please answer the following \"Information Security and Cybersecurity\" topic question based on your understanding and the information provided and find relevant links, image names, tables, pages, content sources in the information, following the structure defined below:**\n",
    "        \n",
    "        Information: {context}\n",
    "        Question: {question}\n",
    "        \n",
    "        **Required instructions:**\n",
    "        <no-content>: no content is presented here.\n",
    "        <content>: The content of that item is presented here.\n",
    "        #heading<level>: <content>: The title of the answer, with additional content\n",
    "        \n",
    "        **The final answer must be translated into Vietnamese according to the structure:**\n",
    "        <no-content>\n",
    "        #heading1: <content>\n",
    "            <no-content>\n",
    "            ##heading1.1: <content>\n",
    "                <no-content>\n",
    "                ###heading1.1.1: <content>\n",
    "                    <no-content>\n",
    "                    ####heading1.1.1.1: <content>\n",
    "                        <no-content>\n",
    "                    <no-content>\n",
    "                <no-content>\n",
    "                ###heading1.1.2: <content>\n",
    "                    <no-content>\n",
    "                <no-content>\n",
    "            <no-content>\n",
    "        <no-content>\n",
    "        #heading2: <content>\n",
    "            <no-content>\n",
    "            #heading2.1: <content>\n",
    "                <no-content>\n",
    "            <no-content>\n",
    "        <no-content>\n",
    "        **images**: https://example.com/images1, https://example.com/images2, ...\n",
    "        **tables**: https://example.com/tables1, https://example.com/tables2, ...\n",
    "        **pages**: https://example.com/pages1, https://example.com/pages2, ...\n",
    "        **sources**: https://example.com/sources1, https://example.com/sources2, ...\n",
    "        \n",
    "        Question example: Xác thực 2 yếu tố là gì?\n",
    "        Output example: \n",
    "        #heading1: Xác thực hai yếu tố (2FA) là một biện pháp bảo mật bổ sung yêu cầu người dùng cung cấp hai hình thức xác minh khác nhau để đăng nhập vào tài khoản của họ.\n",
    "        #heading2: Các loại xác thực 2FA\n",
    "            ##heading2.1: Yếu tố đầu tiên: Thông thường là tên người dùng và mật khẩu.\n",
    "            ##heading2.2: Yếu tố thứ hai: Có thể bao gồm:\n",
    "                ###heading2.2.1: Mã OTP (One-Time Password) được gửi qua SMS hoặc email.\n",
    "                ###heading2.2.2: Ứng dụng xác thực trên điện thoại di động (ví dụ: Google Authenticator, Authy).\n",
    "                ###heading2.2.3: Dòng chữ ký vật lý (FIDO2).\n",
    "                ###heading2.2.4: Chuyển đổi sinh trắc học (nhận dạng khuôn mặt, vân tay).\n",
    "        #heading3: Lợi ích của Xác thực 2FA\n",
    "            ##heading3.1: Xác thực 2FA giúp tăng cường bảo mật tài khoản bằng cách làm cho việc truy cập trái phép trở nên khó khăn hơn đáng kể. Bằng cách yêu cầu hai yếu tố xác minh, 2FA ngăn chặn kẻ tấn công có được quyền truy cập vào tài khoản của bạn ngay cả khi họ biết tên người dùng và mật khẩu của bạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---evaluate----\n",
    "\n",
    "TODO_LIST = [\n",
    "    \"\"\"**Đánh giá và cập nhật chính sách bảo mật định kỳ để phù hợp với tiêu chuẩn SOC 2, ISO 27001, NIST và các quy định như GDPR, HIPAA**\"\"\",\n",
    "    \"\"\"**Xây dựng chiến lược quản lý rủi ro dựa trên đánh giá rủi ro an ninh mạng định kỳ**\"\"\",\n",
    "    \"\"\"**Đảm bảo tổ chức tuân thủ các tiêu chuẩn bảo mật thông qua đánh giá và chứng nhận định kỳ bởi bên thứ ba**\"\"\",\n",
    "    \"\"\"**Thiết lập Trung tâm Giám sát An ninh (SOC) để giám sát 24/7**\"\"\",\n",
    "    \"\"\"**Thực hiện kiểm tra xâm nhập (Penetration Testing) hàng năm để xác định lỗ hổng**\"\"\",\n",
    "    \"\"\"**Sử dụng các công cụ như SIEM để phân tích và phản ứng nhanh với các sự kiện an ninh**\"\"\",\n",
    "    \"\"\"**Theo dõi và phân tích nhật ký bảo mật để phát hiện các bất thường**\"\"\",\n",
    "    \"\"\"**Mã hóa dữ liệu tại chỗ (at-rest) và khi truyền tải (in-transit) bằng giao thức mạnh như AES-256**\"\"\",\n",
    "    \"\"\"**Phân loại dữ liệu theo độ nhạy cảm và áp dụng các biện pháp bảo mật phù hợp**\"\"\",\n",
    "    \"\"\"**Triển khai xác thực đa yếu tố (MFA) cho mọi truy cập quan trọng**\"\"\",\n",
    "    \"\"\"**Định kỳ kiểm tra và thu hồi quyền truy cập không còn sử dụng**\"\"\",\n",
    "    \"\"\"**Thực hiện chính sách \\\"Least Privilege\\\" để giảm thiểu quyền truy cập dư thừa**\"\"\",\n",
    "    \"\"\"**Đảm bảo bảo mật vật lý tại các trung tâm dữ liệu, văn phòng bằng khóa cửa, camera giám sát, và hệ thống kiểm soát ra vào**\"\"\",\n",
    "    \"\"\"**Bảo vệ các thiết bị đầu cuối (endpoint) bằng các giải pháp EDR và phần mềm chống malware**\"\"\",\n",
    "    \"\"\"**Áp dụng chính sách bảo mật di động, bao gồm mã hóa dữ liệu trên thiết bị cá nhân**\"\"\",\n",
    "    \"\"\"**Xây dựng kế hoạch ứng phó sự cố an ninh thông tin (IRP) chi tiết và tổ chức diễn tập định kỳ**\"\"\",\n",
    "    \"\"\"**Thành lập nhóm phản ứng nhanh với sự cố (Incident Response Team)**\"\"\",\n",
    "    \"\"\"**Thực hiện phân tích nguyên nhân gốc rễ (Root Cause Analysis) sau mỗi sự cố**\"\"\",\n",
    "    \"\"\"**Triển khai chương trình đào tạo nhận thức an ninh mạng cho toàn bộ nhân viên**\"\"\",\n",
    "    \"\"\"**Tổ chức các bài kiểm tra mô phỏng (phishing simulation) để nâng cao khả năng nhận diện nguy cơ**\"\"\",\n",
    "    \"\"\"**Thiết lập quy trình quản lý thay đổi (Change Management) để đảm bảo mọi thay đổi đều được phê duyệt và giám sát**\"\"\",\n",
    "    \"\"\"**Cập nhật bản vá bảo mật định kỳ cho tất cả hệ thống và ứng dụng**\"\"\",\n",
    "    \"\"\"**Áp dụng công cụ tự động hóa để giảm thiểu lỗi con người trong việc triển khai thay đổi**\"\"\",\n",
    "    \"\"\"**Đánh giá định kỳ về chính sách bảo mật của nhà cung cấp bên ngoài**\"\"\",\n",
    "    \"\"\"**Thiết lập hợp đồng với các điều khoản bảo mật và trách nhiệm rõ ràng cho đối tác**\"\"\",\n",
    "    \"\"\"**Triển khai hệ thống phát hiện và ngăn chặn xâm nhập (IDS/IPS)**\"\"\",\n",
    "    \"\"\"**Thiết lập giải pháp phòng chống DDoS cho các hệ thống công khai**\"\"\",\n",
    "    \"\"\"**Giám sát các xu hướng tấn công mới để điều chỉnh chiến lược phòng ngừa**\"\"\",\n",
    "    \"\"\"**Thực hiện kiểm tra tính khả dụng và hiệu quả của hệ thống sao lưu và khôi phục dữ liệu**\"\"\",\n",
    "    \"\"\"**Xây dựng và kiểm tra kế hoạch khôi phục sau thảm họa (Disaster Recovery Plan) định kỳ**\"\"\",\n",
    "]\n",
    "\n",
    "n_TODO = len(TODO_LIST)\n",
    "\n",
    "TODO_LIST_STR = \"\\n\".join([f\"{i + 1}. {item}\" for i, item in enumerate(TODO_LIST)])\n",
    "\n",
    "def process_result_of_evaluate(result: str) -> list[int]:\n",
    "    newresult = ''.join((ch if ch in '0123456789.-e' else ' ') for ch in result)\n",
    "    listOfNumbers = [int(i) for i in newresult.split() if i.isdigit() and int(i) > 0 and int(i) <= n_TODO]\n",
    "    return listOfNumbers\n",
    "\n",
    "def get_evaluate_template(todo_list_str: str, content: str) -> dict:\n",
    "    \"\"\"Query with vector db\"\"\"\n",
    "    \n",
    "    template = f\"\"\"\n",
    "        You are the ChatBot that helps evaluate which \"content\" meets which to-do in the \"To-Do List\" in the security domain we provide you.\n",
    "        \n",
    "        Required:\n",
    "        **Do not create any additional content. **\n",
    "        **Strict evaluation with high precision and rigor, no ambiguous answers that distort the results.**\n",
    "        **For each \"to-do\", if the \"to-do\" has been clearly presented in the \"content\", the output must contain the location of that \"to-do\" and not include the content of that location.**\n",
    "        **If it cannot be evaluated or the evaluation is unclear during the evaluation, skip the \"to-do\".**\n",
    "        **If the evaluation result has more than 5 satisfied \"to-do\" locations, you need to consider especially carefully and especially strictly before giving the final result**\n",
    "        **The final answer must be a list of \"to-do\" location numbers obtained from the above evaluation separated by \",\"**\n",
    "        **If there is no satisfactory \"to-do\", the output must be: -1**\n",
    "        \n",
    "        To-do list: {todo_list_str}\n",
    "        Content: {content}\n",
    "        \n",
    "        Example output 1: 1, 2, 3\n",
    "        Example output 2: 3, 7, 12, 23\n",
    "        Example output 3: -1\n",
    "    \"\"\"\n",
    "\n",
    "    return template\n",
    "\n",
    "#---End---evaluate----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---save file----\n",
    "\n",
    "def check_file_type(file_path: str):\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    return file_extension.lower().split(\".\")[-1]\n",
    "\n",
    "def get_file_name(file_path: str):\n",
    "    file_name = file_path.split('\\\\')[-1]\n",
    "    folder_path = file_path.split('\\\\')[:-1]\n",
    "    return file_name\n",
    "\n",
    "def get_folder_abs_path(user_id: str) -> str:\n",
    "    if not os.path.exists(DB_DIRECTORY):\n",
    "        os.makedirs(DB_DIRECTORY)\n",
    "\n",
    "    folder = DB_DIRECTORY + user_id\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    folder_abs_path = os.path.abspath(folder)\n",
    "    return folder_abs_path\n",
    "\n",
    "async def save_pdf(file: str, user_id: str) -> str:\n",
    "    folder_abs_path = get_folder_abs_path(user_id)\n",
    "    \n",
    "    pdf_content = await file.read()\n",
    "    file_name = file.filename\n",
    "    file_abs_path = os.path.join(folder_abs_path, file_name)\n",
    "\n",
    "    with open(file_abs_path, \"wb\") as output_file:\n",
    "        output_file.write(pdf_content)\n",
    "    \n",
    "    return file_abs_path\n",
    "    \n",
    "def get_check_is_socreport_template(sample_content: str):\n",
    "    template = f\"\"\"\n",
    "        Are you a chatbot that helps classify whether the provided \"content sample\" is part of the \"SOC report\" content?\n",
    "        \n",
    "        Content sample: {sample_content}\n",
    "        \n",
    "        **Required:**\n",
    "        **No additional content is generated.**\n",
    "        **The final answer is True or False.**\n",
    "        **If there is no result or cannot be evaluated or the result is unclear and ambiguous during the evaluation, the answer must be: False**\n",
    "        \n",
    "        Example output 1: True\n",
    "        Example output 2: False\n",
    "        Example output 3: True\n",
    "    \"\"\"\n",
    "    return template\n",
    "    \n",
    "async def check_is_socreport_file(sample_content: str):\n",
    "    template = get_check_is_socreport_template(sample_content)\n",
    "    result = await generate_result(template, False)\n",
    "    result = result.lower().strip()\n",
    "    \n",
    "    if result.lower() == \"true\": return True\n",
    "    return False\n",
    "    \n",
    "    \n",
    "#---End---save file----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---create file PDF----\n",
    "\n",
    "def initialize_pdf():\n",
    "    pdf = FPDF('P', 'mm', 'A4')\n",
    "    pdf.add_page()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_font(\"DejaVu\", \"\", \"soc-fonts/DejaVuSans.ttf\", uni=True)\n",
    "    pdf.add_font(\"DejaVu-Bold\", \"\", \"soc-fonts/DejaVuSans-Bold.ttf\", uni=True)\n",
    "    pdf.add_font(\"DejaVu-Italic\", \"\", \"soc-fonts/DejaVuSerif-Italic.ttf\", uni=True)\n",
    "    return pdf\n",
    "\n",
    "def add_header(pdf, title:str):\n",
    "    pdf.set_font(\"Arial\", 'B', 16)\n",
    "    pdf.cell(0, 10, title, 0, 1, 'C')\n",
    "\n",
    "def add_section_title(pdf, title:str):\n",
    "    pdf.set_font(\"Arial\", 'B', 14)\n",
    "    pdf.cell(0, 10, title, 0, 1)\n",
    "\n",
    "def add_task_list(pdf, todo_list:list[str], indices:dict, title:str):\n",
    "    add_section_title(pdf, title)\n",
    "    pdf.set_font(\"DejaVu\", '', 13)\n",
    "    line_height = 10\n",
    "    \n",
    "    for i, (key, value) in enumerate(indices.items()):\n",
    "        if key < 0 or key >= len(todo_list): continue\n",
    "    \n",
    "        checkbox = \"\\u2611\" if value else \"\\u2610\"\n",
    "        title_number = \"1\" if value else \"2\"\n",
    "        parts = todo_list[key].split(\"**\")\n",
    "        \n",
    "        pdf.set_x(pdf.get_x() + 10)\n",
    "        pdf.set_font(\"DejaVu-Bold\", '', 13)\n",
    "        pdf.multi_cell(0, line_height, f\"{title_number}.{i+1}. {checkbox} {parts[1].strip()}\" , 0)\n",
    "\n",
    "        # pdf.set_x(pdf.get_x() + 10)\n",
    "        # pdf.set_font(\"DejaVu\", '', 13)\n",
    "        # pdf.multi_cell(0, line_height, f\"\\u279B{parts[2].strip()}\", 0)\n",
    "        \n",
    "        # if value:\n",
    "        #     pdf.set_x(pdf.get_x() + 10)\n",
    "        #     pdf.set_font(\"DejaVu-Italic\", '', 13)\n",
    "        #     pdf.multi_cell(0, line_height, f\"\\u201C\\u2026{value.page_content.strip()}\\u2026\\u201D\", 0)\n",
    "            \n",
    "        pdf.ln(5)\n",
    "\n",
    "def create_information_security_evaluation(todo_list:list[str], completed_indices:dict, user_id:str, file_evaluation_name:str=\"Information_Security_Evaluation.pdf\") -> str:\n",
    "    folder_abs_path = get_folder_abs_path(user_id)\n",
    "    output_path = os.path.join(folder_abs_path, file_evaluation_name)\n",
    "    \n",
    "    pdf = initialize_pdf()\n",
    "    add_header(pdf, \"Information Security Evaluation\")\n",
    "    \n",
    "    add_task_list(pdf, todo_list, completed_indices, \"1. Completed Tasks\",)\n",
    "    pdf.add_page()\n",
    "    \n",
    "    uncompleted_positions = set(range(len(todo_list))) - set(completed_indices.keys())\n",
    "    uncompleted_positions = {pos: None for pos in uncompleted_positions}\n",
    "    add_task_list(pdf , todo_list, uncompleted_positions, \"2. Pending Tasks\")\n",
    "    \n",
    "    pdf.output(output_path)\n",
    "    return file_evaluation_name, output_path\n",
    "\n",
    "#---End---create file PDF----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---document----\n",
    "\n",
    "def get_raw_documents(file_path: str):\n",
    "    file_type = check_file_type(file_path)\n",
    "    if file_type == \"pdf\":\n",
    "        raw_documents = PyPDFLoader(file_path).load()\n",
    "    elif file_type == \"docx\":\n",
    "        raw_documents = Docx2txtLoader(file_path).load()\n",
    "    elif file_type == \"txt\":\n",
    "        raw_documents = TextLoader(file_path, encoding = 'UTF-8').load()\n",
    "    else:\n",
    "        return []\n",
    "    return raw_documents\n",
    "    \n",
    "def process_raw_documents(raw_documents: list[Document]) -> list[Document]: \n",
    "    source = get_file_name(raw_documents[0].metadata.get('source'))\n",
    "    for idx, raw_document in enumerate(raw_documents):\n",
    "        page = raw_document.metadata.get('page')\n",
    "        metadata = {'source': source, 'page': page}\n",
    "        setattr(raw_document, 'metadata', metadata)\n",
    "    return raw_documents\n",
    "    \n",
    "def get_documents(file_path: str) -> list[Document]:\n",
    "    raw_documents = get_raw_documents(file_path)\n",
    "    documents = process_raw_documents(raw_documents)\n",
    "    return documents\n",
    "    \n",
    "def get_texts(file_path: str) -> (str, str):\n",
    "    raw_documents = get_raw_documents(file_path)\n",
    "    source = raw_documents[0].metadata.get('source').split('\\\\')[-1]\n",
    "    page_content = \"\"\n",
    "    for raw_document in raw_documents:\n",
    "        page_content += raw_document.page_content\n",
    "    return source, page_content\n",
    "\n",
    "def process_documents_before_store(documents: list[Document]) -> list[Document]:\n",
    "    pre_page = 0\n",
    "    for index, document in enumerate(documents):\n",
    "        size = len(document.page_content)\n",
    "        metadata = document.metadata\n",
    "        metadata['size'] = size\n",
    "        metadata['index'] = index\n",
    "        metadata['pre_page'] = pre_page\n",
    "        pre_page = metadata.get('page')\n",
    "        setattr(document, 'metadata', metadata)\n",
    "        \n",
    "    return documents\n",
    "\n",
    "def split_documents_file_common(file_path: str) -> list[Document]:\n",
    "    text_splitter = SemanticChunker(\n",
    "        embeddings=embeddings, \n",
    "        breakpoint_threshold_type=\"percentile\", \n",
    "        number_of_chunks=1024\n",
    "    )\n",
    "    \n",
    "    documents = get_documents(file_path)\n",
    "    documents = text_splitter.split_documents(documents)\n",
    "    documents = process_documents_before_store(documents)\n",
    "    return documents\n",
    "    \n",
    "def split_documents_file_soc(file_path: str) -> list[Document]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 4096, \n",
    "        chunk_overlap = 124,\n",
    "        separators = [\n",
    "            \"\\n\\n\",\n",
    "            \"\\n\",\n",
    "            \" \",\n",
    "            \".\",\n",
    "            \",\",\n",
    "            \"\\u200b\",  # Zero-width space\n",
    "            \"\\uff0c\",  # Fullwidth comma\n",
    "            \"\\u3001\",  # Ideographic comma\n",
    "            \"\\uff0e\",  # Fullwidth full stop\n",
    "            \"\\u3002\",  # Ideographic full stop\n",
    "            \"\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    source, page_content = get_texts(file_path)\n",
    "    documents = text_splitter.create_documents([page_content])\n",
    "    return documents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---upload----\n",
    "\n",
    "def upload_to_chroma(docs: list[Document], user_id: str):\n",
    "    vectorstore = existing_collection(user_id)\n",
    "    for i in range(0, len(docs), BATCH_SIZE_UPLOAD):\n",
    "        batch = docs[i:i+BATCH_SIZE_UPLOAD]\n",
    "        vectorstore.add_documents(batch)\n",
    "\n",
    "def upload_common(file_abs_path: str, user_id: str) -> bool:\n",
    "    docs = split_documents_file_common(file_abs_path)\n",
    "    upload_to_chroma(docs, user_id)\n",
    "    return docs[0]\n",
    "    \n",
    "async def upload_soc(file_abs_path: str, user_id: str):\n",
    "    completed_positions = {}\n",
    "    docs = split_documents_file_soc(file_abs_path)\n",
    "    \n",
    "    print(\"Length\", len(docs))\n",
    "    print(\"File name\", file_abs_path)\n",
    "    \n",
    "    for idx, doc in enumerate(docs):\n",
    "        template = get_evaluate_template(TODO_LIST_STR, doc)\n",
    "        print(\"Template size:\", len(template))\n",
    "        \n",
    "        result = await generate_result(template, False)\n",
    "        completed_position_list = process_result_of_evaluate(result)\n",
    "            \n",
    "        for completed_position in completed_position_list:\n",
    "            completed_positions[completed_position] = doc\n",
    "        \n",
    "        print(\"Done index: \", idx, \"result: \", result, \"completed_position_list: \", completed_position_list)\n",
    "        print(\"completed_positions: \", completed_positions.keys())\n",
    "        \n",
    "        create_information_security_evaluation(TODO_LIST, completed_positions, user_id)\n",
    "        if len(completed_position_list) == n_TODO: \n",
    "            break\n",
    "        \n",
    "        print(\"--------------------------------------------------------------------------\")\n",
    "            \n",
    "    file_evaluation_name, pdf_output_path = create_information_security_evaluation(TODO_LIST, completed_positions, user_id)\n",
    "    print(\"Completed positions\", completed_positions.keys())\n",
    "    print(f\"File evaluation name: {file_evaluation_name}\")\n",
    "    print(f\"PDF output path: {pdf_output_path}\")\n",
    "    \n",
    "    return file_evaluation_name, pdf_output_path\n",
    "    \n",
    "async def background_upload_soc(user_query: str, file_abs_path: str, user_id: str):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    file_evaluation_name, pdf_output_path = await upload_soc(file_abs_path, user_id)\n",
    "    print(\"file_evaluation_name, pdf_output_path: \", file_evaluation_name, pdf_output_path)\n",
    "    \n",
    "    email_receiver = get_email_receiver(user_query)\n",
    "    print(email_receiver)\n",
    "\n",
    "    success = await loop.run_in_executor(\n",
    "        None,\n",
    "        lambda: send_email_with_attachment(email_receiver, file_evaluation_name, pdf_output_path)\n",
    "    )\n",
    "    \n",
    "    return success\n",
    "\n",
    "#---End---upload----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Start---API----\n",
    "\n",
    "@app.post(\"/llms\")\n",
    "async def post_llms(\n",
    "    template: str = Form(...)\n",
    "):\n",
    "    \n",
    "    return StreamingResponse(\n",
    "        generate_stream_json(template, True), media_type='text/event-stream'\n",
    "    )\n",
    "\n",
    "@app.post(\"/ask\")\n",
    "async def post_ask(\n",
    "    user_id: str = Form(...), \n",
    "    user_query: str = Form(...)\n",
    "):\n",
    "    \n",
    "    template = await get_ask_template(user_id, user_query)\n",
    "    print(\"ask\", user_id)\n",
    "    print(\"ask\", user_query)\n",
    "    print(\"template\", len(template))\n",
    "    \n",
    "    return StreamingResponse(\n",
    "        generate_stream_json(template, True), media_type='text/event-stream'\n",
    "    )\n",
    "\n",
    "@app.post(\"/upload\")\n",
    "async def post_upload(\n",
    "    user_id: str = Form(...), \n",
    "    user_query: str = Form(...),\n",
    "    file: UploadFile = File(...),\n",
    "    background_tasks: BackgroundTasks = BackgroundTasks()\n",
    "):\n",
    "    \n",
    "    print(\"upload-common\", user_id)\n",
    "    print(\"upload-common\", file.filename)\n",
    "    \n",
    "    if file and user_id:\n",
    "        file_abs_path = await save_pdf(file, user_id)\n",
    "        sample_content = upload_common(file_abs_path, user_id)\n",
    "        \n",
    "        is_socreport_file = False\n",
    "        # is_socreport_file = await check_is_socreport_file(sample_content)\n",
    "        # print(\"is_socreport_file: \", is_socreport_file)\n",
    "        \n",
    "        response = \"#heading1: Tải lên file thành công! Giờ đây bạn có thể truy cập thông tin trong các file vừa gửi lên, câu trả lời sẽ sớm được phản hồi vui lòng chờ!\"\n",
    "        if is_socreport_file:\n",
    "            background_tasks.add_task(background_upload_soc, user_query, file_abs_path, user_id)\n",
    "            response = \"\"\"\n",
    "                #heading1: Tải lên file thành công!\n",
    "                #heading2: Giờ đây bạn có thể truy cập thông tin trong các file vừa gửi lên trong khi đó chúng tôi sẽ xem xét và đánh giá bảo mật file báo cáo SOC 2 type II của bạn!\n",
    "                #heading3: Kết quả sẽ được gửi qua Gmail của bạn vừa cung cấp!\n",
    "            \"\"\"\n",
    "        \n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                \"is_socreport_file\": is_socreport_file,\n",
    "                \"response\": response,\n",
    "                \"success\": True\n",
    "            },\n",
    "            status_code=200 \n",
    "        )\n",
    "    \n",
    "    return JSONResponse(\n",
    "        content={\n",
    "            \"response\": \"Tải lên file không thành công, vui lòng kiểm tra lại file pdf của bạn!\",\n",
    "            \"success\": False\n",
    "        },\n",
    "        status_code=200 \n",
    "    )\n",
    "\n",
    "#---End---API----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    config = Config(\n",
    "        app=app,\n",
    "        host=\"0.0.0.0\",\n",
    "        port=7722,\n",
    "        log_level=\"debug\",\n",
    "        log_config=None,\n",
    "        use_colors=False\n",
    "    )\n",
    "    \n",
    "    server = Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
